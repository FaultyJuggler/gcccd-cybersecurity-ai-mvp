{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Malware Classification using CNN with LLM Mitigation Recommendations\n",
    "\n",
    "This notebook demonstrates how to train a Convolutional Neural Network (CNN) for malware classification and uses an LLM to generate mitigation recommendations for detected malware."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Setup and Data Preparation\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# PyTorch imports (replacing TensorFlow)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Configure device for computation\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    print(\"CUDA acceleration enabled\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Apple Silicon (MPS) acceleration enabled\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU acceleration available, using CPU\")\n",
    "\n",
    "# Verify PyTorch device and version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Data Analysis and Preparation\n",
    "\n",
    "Let's analyze the dataset structure and prepare it for training."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define data directories\n",
    "base_dir = 'data'\n",
    "benign_dir = os.path.join(base_dir, 'benign')\n",
    "malicious_dir = os.path.join(base_dir, 'malicious')\n",
    "\n",
    "# Choose which size and interpolation method to use\n",
    "SIZE = '600'  # Options: '120', '300', '600', '1200'\n",
    "INTERPOLATION = 'nearest'  # Options: 'nearest', 'lanczos'\n",
    "\n",
    "# Create paths for the selected size and interpolation\n",
    "benign_path = os.path.join(benign_dir, f'{INTERPOLATION}_{SIZE}')\n",
    "malicious_path = os.path.join(malicious_dir, f'{INTERPOLATION}_{SIZE}')\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Using {SIZE}x{SIZE} images with {INTERPOLATION} interpolation\")\n",
    "print(f\"\\nNumber of benign samples: {len(os.listdir(benign_path))}\")\n",
    "print(f\"Number of malicious samples: {len(os.listdir(malicious_path))}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Data Loading and Preprocessing\n",
    "\n",
    "Set up the data generators for training and validation."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Image parameters\n",
    "IMG_HEIGHT = int(SIZE)\n",
    "IMG_WIDTH = int(SIZE)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data transformations for training\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1] for grayscale\n",
    "])\n",
    "\n",
    "# Transformations for validation (no augmentation)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "full_dataset = datasets.ImageFolder(root=base_dir, transform=None)\n",
    "\n",
    "# Calculate split sizes\n",
    "total_size = len(full_dataset)\n",
    "val_size = int(0.2 * total_size)\n",
    "train_size = total_size - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Apply transforms\n",
    "train_dataset.dataset.transform = train_transforms\n",
    "val_dataset.dataset.transform = val_transforms\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# Print class information\n",
    "class_names = full_dataset.classes\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Class to idx mapping: {full_dataset.class_to_idx}\")\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Data Visualization\n",
    "\n",
    "Let's visualize some samples from both classes."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_sample_images():\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot benign samples\n",
    "    benign_files = os.listdir(benign_path)[:5]\n",
    "    for i, file_name in enumerate(benign_files):\n",
    "        img_path = os.path.join(benign_path, file_name)\n",
    "        img = plt.imread(img_path)\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title('Benign')\n",
    "        plt.axis('off')\n",
    "\n",
    "    # Plot malicious samples\n",
    "    malicious_files = os.listdir(malicious_path)[:5]\n",
    "    for i, file_name in enumerate(malicious_files):\n",
    "        img_path = os.path.join(malicious_path, file_name)\n",
    "        img = plt.imread(img_path)\n",
    "        plt.subplot(2, 5, i+6)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title('Malicious')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize raw image samples\n",
    "plot_sample_images()\n",
    "\n",
    "# Function to visualize samples from PyTorch DataLoader\n",
    "def plot_batch_samples(data_loader, title=\"Sample Batch\"):\n",
    "    # Get a batch of images\n",
    "    images, labels = next(iter(data_loader))\n",
    "\n",
    "    # Convert from tensor to numpy for display\n",
    "    images = images.cpu().numpy()\n",
    "\n",
    "    # Create a grid of images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(min(10, len(images))):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        # For normalized data, we need to denormalize: x = (x * 0.5) + 0.5\n",
    "        img = (images[i][0] * 0.5) + 0.5  # [0] selects the channel\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"{class_names[labels[i]]}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples from training data (with augmentation)\n",
    "plot_batch_samples(train_loader, \"Training Samples (with augmentation)\")\n",
    "\n",
    "# Visualize samples from validation data\n",
    "plot_batch_samples(val_loader, \"Validation Samples\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. CNN Model Architecture\n",
    "\n",
    "Create a CNN model for binary classification."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MalwareCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MalwareCNN, self).__init__()\n",
    "\n",
    "        # First Convolutional Block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        # Third Convolutional Block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        # Fourth Convolutional Block\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        # Calculate the flattened size based on input dimensions\n",
    "        # For input size IMG_HEIGHT x IMG_WIDTH, after 4 pooling layers (each /2)\n",
    "        flat_features = 256 * (IMG_HEIGHT // 16) * (IMG_WIDTH // 16)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flat_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Create model and move to device\n",
    "model = MalwareCNN().to(device)\n",
    "\n",
    "# Print model summary (optional - can use torchsummary package)\n",
    "print(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Train the model with early stopping and model checkpointing."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "# Initialize variables to track best model\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "patience_limit = 10  # For early stopping\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nStarting epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)  # Adjust for binary classification\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track statistics\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate epoch statistics\n",
    "    epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "    epoch_train_acc = train_correct / train_total\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate epoch statistics\n",
    "    epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "    epoch_val_acc = val_correct / val_total\n",
    "\n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step(epoch_val_loss)\n",
    "\n",
    "    # Save history\n",
    "    history['train_loss'].append(epoch_train_loss)\n",
    "    history['train_acc'].append(epoch_train_acc)\n",
    "    history['val_loss'].append(epoch_val_loss)\n",
    "    history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f\"Completed epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Training loss: {epoch_train_loss:.4f}, Training accuracy: {epoch_train_acc:.4f}\")\n",
    "    print(f\"Validation loss: {epoch_val_loss:.4f}, Validation accuracy: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    # Check if this is the best model\n",
    "    if epoch_val_acc > best_val_acc:\n",
    "        best_val_acc = epoch_val_acc\n",
    "        patience_counter = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(\"New best model saved!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # Early stopping\n",
    "    if patience_counter >= patience_limit:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
    "        break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Training Visualization\n",
    "\n",
    "Visualize the training process."
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history['train_acc'])\n",
    "    ax1.plot(history['val_acc'])\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'], loc='lower right')\n",
    "\n",
    "    # Plot loss\n",
    "    ax2.plot(history['train_loss'])\n",
    "    ax2.plot(history['val_loss'])\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs > 0.5).float().squeeze()\n",
    "\n",
    "        # For multi-sample batches\n",
    "        if labels.size(0) > 1:\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels.float()).sum().item()\n",
    "        else:  # Handle single-sample batches\n",
    "            all_preds.append(predicted.cpu().item())\n",
    "            all_labels.append(labels.cpu().item())\n",
    "            val_total += 1\n",
    "            val_correct += (predicted == labels.float()).item()\n",
    "\n",
    "val_accuracy = val_correct / val_total\n",
    "print(f'\\nValidation accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "all_preds = np.array(all_preds).astype(int)\n",
    "all_labels = np.array(all_labels).astype(int)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(all_labels, all_preds, target_names=['Benign', 'Malicious']))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Model Evaluation\n",
    "\n",
    "Evaluate the model on the validation set."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the best model for evaluation\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables for tracking metrics\n",
    "val_loss = 0.0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# No gradient calculation needed for evaluation\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Convert outputs to predictions (binary classification)\n",
    "        predictions = (outputs > 0.5).float().squeeze()\n",
    "\n",
    "        # Collect predictions and true labels for metrics\n",
    "        if len(labels.shape) > 0 and labels.shape[0] > 1:  # Batch has multiple samples\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predictions == labels.float()).sum().item()\n",
    "        else:  # Handle single-sample batch\n",
    "            y_pred.append(predictions.cpu().item())\n",
    "            y_true.append(labels.cpu().item())\n",
    "            val_total += 1\n",
    "            val_correct += (predictions == labels.float()).item()\n",
    "\n",
    "# Calculate accuracy\n",
    "val_accuracy = val_correct / val_total\n",
    "print(f'\\nValidation accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Convert to numpy arrays for sklearn metrics\n",
    "y_pred = np.array(y_pred).astype(int)\n",
    "y_true = np.array(y_true).astype(int)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_true, y_pred, target_names=['Benign', 'Malicious']))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. LLM Integration for Mitigation Recommendations\n",
    "\n",
    "Use an LLM to generate mitigation recommendations for detected malware."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_mitigation_recommendations(malware_type, confidence_score):\n",
    "    \"\"\"Get mitigation recommendations from an LLM API.\"\"\"\n",
    "    # Replace with your actual API endpoint and key\n",
    "    API_ENDPOINT = \"ENDPOINT\"\n",
    "    AUTH_SEK = \"KEY\"\n",
    "    \n",
    "    prompt = f\"\"\"Given a malware detection with the following details:\n",
    "    - Malware Type: {malware_type}\n",
    "    - Detection Confidence: {confidence_score:.2%}\n",
    "    \n",
    "    Please provide:\n",
    "    1. A brief description of this type of malware\n",
    "    2. Immediate mitigation steps\n",
    "    3. Long-term prevention measures\n",
    "    4. Any specific tools or software recommended for removal\n",
    "    \n",
    "    Format the response in markdown with clear sections.\"\"\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {AUTH_SEK}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 500,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_ENDPOINT, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['choices'][0]['text']\n",
    "    except Exception as e:\n",
    "        return f\"Error getting recommendations: {str(e)}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_predictions(predictions, loader=None, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Analyze predictions and get batched mitigation recommendations for malicious samples.\n",
    "\n",
    "    Args:\n",
    "        predictions: Tensor of model predictions\n",
    "        loader: DataLoader containing the validation/test data (optional)\n",
    "        threshold: Confidence threshold for malware detection\n",
    "    \"\"\"\n",
    "    # Move predictions to CPU and convert to numpy\n",
    "    predictions_cpu = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Get indices of malicious predictions\n",
    "    malicious_indices = np.where(predictions_cpu > threshold)[0]\n",
    "\n",
    "    if len(malicious_indices) == 0:\n",
    "        print(\"No malicious samples detected.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nDetected {len(malicious_indices)} malicious samples.\")\n",
    "\n",
    "    # Group samples by confidence score ranges\n",
    "    confidence_groups = {}\n",
    "    for idx in malicious_indices:\n",
    "        confidence = predictions_cpu[idx].item()\n",
    "        # Round confidence to nearest 0.1 for grouping\n",
    "        confidence_group = round(confidence, 1)\n",
    "        if confidence_group not in confidence_groups:\n",
    "            confidence_groups[confidence_group] = {\n",
    "                'indices': [],\n",
    "                'filenames': [],\n",
    "                'count': 0\n",
    "            }\n",
    "        confidence_groups[confidence_group]['indices'].append(idx)\n",
    "        confidence_groups[confidence_group]['count'] += 1\n",
    "\n",
    "        # If loader is provided, try to get filenames\n",
    "        if loader and hasattr(loader.dataset, 'samples'):\n",
    "            try:\n",
    "                # Handle both Dataset and Subset cases\n",
    "                dataset = loader.dataset\n",
    "                if hasattr(dataset, 'dataset'):  # If it's a Subset\n",
    "                    dataset = dataset.dataset\n",
    "                filename = dataset.samples[idx][0]\n",
    "                confidence_groups[confidence_group]['filenames'].append(\n",
    "                    os.path.basename(filename)\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Prepare batched LLM request\n",
    "    llm_requests = []\n",
    "    for confidence, group_data in confidence_groups.items():\n",
    "        request = {\n",
    "            'confidence': confidence,\n",
    "            'sample_count': group_data['count'],\n",
    "            'file_info': group_data['filenames'] if group_data['filenames'] else group_data['indices']\n",
    "        }\n",
    "        llm_requests.append(request)\n",
    "\n",
    "    # Get batched recommendations from LLM\n",
    "    recommendations = get_batched_recommendations(llm_requests)\n",
    "\n",
    "    # Display results\n",
    "    for confidence, group_data in confidence_groups.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Malware Detection Group (Confidence: {confidence:.1%})\")\n",
    "        print(f\"Number of samples: {group_data['count']}\")\n",
    "\n",
    "        # Display sample information\n",
    "        print(\"\\nAffected samples:\")\n",
    "        samples_to_show = group_data['filenames'] if group_data['filenames'] else group_data['indices']\n",
    "        for sample in samples_to_show[:5]:\n",
    "            print(f\"- {sample}\")\n",
    "        if len(samples_to_show) > 5:\n",
    "            print(f\"... and {len(samples_to_show)-5} more\")\n",
    "\n",
    "        # Display recommendations if available\n",
    "        if recommendations and str(confidence) in recommendations:\n",
    "            display(Markdown(recommendations[str(confidence)]))\n",
    "\n",
    "def get_batched_recommendations(requests):\n",
    "    \"\"\"\n",
    "    Get batched mitigation recommendations from LLM API.\n",
    "\n",
    "    Args:\n",
    "        requests: List of dictionaries containing group information\n",
    "    \"\"\"\n",
    "    # API configuration - use environment variables in production\n",
    "    API_ENDPOINT = \"${LLM_API_ENDPOINT}\"  # Replace with actual endpoint\n",
    "    API_KEY = \"${LLM_API_KEY}\"  # Replace with actual API key\n",
    "\n",
    "    # Prepare batched prompt\n",
    "    prompt = \"Analyze the following malware detection groups and provide recommendations:\\n\\n\"\n",
    "    for req in requests:\n",
    "        prompt += f\"\"\"\n",
    "Group with {req['sample_count']} samples (Confidence: {req['confidence']:.1%}):\n",
    "- Sample identifiers: {req['file_info'][:5]}...\n",
    "\n",
    "Please provide:\n",
    "1. Risk assessment for this confidence level\n",
    "2. Immediate mitigation steps\n",
    "3. Long-term prevention measures\n",
    "4. Recommended security tools\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # In production, replace with actual API call\n",
    "        print(\"API call would be made with following headers:\", headers)\n",
    "        print(\"API endpoint:\", API_ENDPOINT)\n",
    "\n",
    "        # Simulated response structure\n",
    "        return {\n",
    "            str(req['confidence']): f\"\"\"\n",
    "### Risk Assessment\n",
    "- Confidence Level: {req['confidence']:.1%}\n",
    "- Severity: {'High' if req['confidence'] > 0.8 else 'Medium' if req['confidence'] > 0.6 else 'Low'}\n",
    "\n",
    "### Immediate Mitigation Steps\n",
    "1. Isolate affected systems\n",
    "2. Run deep scan with updated antivirus\n",
    "3. Block suspicious network connections\n",
    "\n",
    "### Long-term Prevention\n",
    "1. Implement regular security audits\n",
    "2. Update security policies\n",
    "3. Employee security training\n",
    "\n",
    "### Recommended Tools\n",
    "- EDR solutions\n",
    "- Network monitoring tools\n",
    "- Security information and event management (SIEM)\n",
    "\"\"\"\n",
    "            for req in requests\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return f\"Error getting recommendations: {str(e)}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run the analysis on validation predictions\n",
    "analyze_predictions(predictions)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 10. Save the Model\n",
    "\n",
    "Save the trained model for future use."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the trained model\n",
    "def save_model(model, path='malware_classifier.pt', save_entire_model=False):\n",
    "    \"\"\"\n",
    "    Save the PyTorch model.\n",
    "    Args:\n",
    "        model: The PyTorch model to save\n",
    "        path: Path where to save the model\n",
    "        save_entire_model: If True, saves the entire model, otherwise just the state dict\n",
    "    \"\"\"\n",
    "    if save_entire_model:\n",
    "        # Save the entire model\n",
    "        torch.save(model, path)\n",
    "        print(f\"Entire model saved to {path}\")\n",
    "    else:\n",
    "        # Save only the model's state dictionary (recommended approach)\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f\"Model state dict saved to {path}\")\n",
    "\n",
    "    # Also save as TorchScript model for deployment\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    example_input = torch.randn(1, 1, IMG_HEIGHT, IMG_WIDTH).to(device)  # Example input\n",
    "    traced_model = torch.jit.trace(model, example_input)\n",
    "    scripted_path = path.replace('.pt', '_scripted.pt')\n",
    "    traced_model.save(scripted_path)\n",
    "    print(f\"TorchScript model saved to {scripted_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
